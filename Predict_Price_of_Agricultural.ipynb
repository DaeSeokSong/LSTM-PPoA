{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict Price of Agricultural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/FXR4DLHyMVW1zs6rHOq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/LSTM-PPoA/blob/main/Predict_Price_of_Agricultural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUHp2QmQfL70"
      },
      "source": [
        "# 참조문헌\n",
        "## [A Prediction Model for Agricultural Products Price with LSTM Network](https://www.koreascience.or.kr/article/JAKO201809469053682.page)\n",
        "\n",
        "**신성호, 이미경, 송사광**\n",
        "\n",
        "한국과학기술정보연구원 연구데이터플랫폼센터,\n",
        "한국과학기술정보연구원 연구데이터플랫폼센터/과학기술연합대학원대학교 빅데이터과학과\n",
        "\n",
        "Sungho Shin(maximus74@kisti.re.kr), Mikyoung Lee(jerryis@kisti.re.kr),\n",
        "Sa-kwang Song(esmallj@kisti.re.kr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFNr9uiwNDj"
      },
      "source": [
        "\n",
        "---\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuQW7ij4HGQc"
      },
      "source": [
        "# 당년 농산물 가격 예측 LSTM 모델\n",
        "\n",
        "Input = 1~저번 달까지의 pram 값을 하나로 묶은 array(인스턴스)\n",
        "\n",
        "output = 당월의 해당 채소 가격\n",
        "\n",
        "layer = 원래 해당 채소 가격"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8AkO_e7n4kv"
      },
      "source": [
        "### Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imYIsQ-Qn6oB",
        "outputId": "e24ce503-4a3d-45a5-f1ac-2f12f8028407"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/DeepLearning/Project/PPoA\n",
        "!ls -al"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/DeepLearning/Project/PPoA\n",
            "total 69\n",
            "drwx------ 2 root root  4096 Nov 24 06:07  Dataset\n",
            "-rw------- 1 root root 66479 Nov 27 13:28 'Predict Price of Agricultural.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urjpqmlxb99Q"
      },
      "source": [
        "### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjLL_CiwGa2v"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import metrics, losses\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76aV88cLGCI-"
      },
      "source": [
        "### Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v5fm5afGCRQ"
      },
      "source": [
        "def Normalization(targetData) :\n",
        "    return (targetData - targetData.min()) / (targetData.max() - targetData.min())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ER3CZzLmvJz"
      },
      "source": [
        "### Global variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slotXBAvmvRp"
      },
      "source": [
        "TARGET_YEAR = 2020\n",
        "START_YEAR = 0\n",
        "END_YEAR = 0\n",
        "CROPS = ''"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbsM_WkpdNAn"
      },
      "source": [
        "### Data read"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_evTlykE11UA"
      },
      "source": [
        "##### Trained data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li41MIACdNGY"
      },
      "source": [
        "START_YEAR = 2006\n",
        "END_YEAR = 2019\n",
        "CROPS = 'onion'\n",
        "dataset = []\n",
        "\n",
        "# 지난 최대 5년간 최대, 최소치를 기준으로 정규화해야 하는 항목들\n",
        "df = pd.read_csv('./Dataset/'+CROPS+'/last_production_'+CROPS+'.csv', index_col=0, encoding='cp949')\n",
        "# 전년 재배면적\n",
        "last_cultiv_area = df['전년면적']\n",
        "# 전년 평균 생산량(수확량)\n",
        "last_production = df['전년생산량']\n",
        "# 전년 평균 생산단수\n",
        "last_prod_unit = df['전년단수']\n",
        "last_prams = [last_cultiv_area,                    # 전년 재배면적\n",
        "            last_production,                       # 전년 평균 생산량\n",
        "            last_prod_unit                         # 전년 평균 생산단수\n",
        "            ]\n",
        "\n",
        "for next in range(0, (END_YEAR-START_YEAR)+1) :\n",
        "    cur_year = START_YEAR + next\n",
        "\n",
        "    f_name = str(cur_year)+'_'+CROPS+'.csv'\n",
        "    df = pd.read_csv('./Dataset/'+CROPS+'/'+f_name, index_col=0)\n",
        "\n",
        "    ''' 기상변수 '''\n",
        "    # 강수량\n",
        "    precipi_avg = df['평균월강수량(mm)']\n",
        "    precipi_max = df['최다월강수량(mm)']\n",
        "    # 기온\n",
        "    temper_avg = df['평균기온(℃)']\n",
        "    temper_max = df['평균최고기온(℃)']\n",
        "    temper_min = df['평균최저기온(℃)']\n",
        "    # 풍속\n",
        "    windSpeed_avg = df['평균풍속(m/s)']\n",
        "    windSpeed_max = df['최대풍속(m/s)']\n",
        "    # 습도\n",
        "    humidity_avg = df['평균습도(%rh)']\n",
        "    humidity_min = df['최저습도(%rh)']\n",
        "    # 일조량 / 일사량\n",
        "    sunshine = df['일조합']\n",
        "    insolation = df['일사합']\n",
        "\n",
        "    ''' 기타변수 '''\n",
        "    # 전년 수입량\n",
        "    last_amount_import = df['전년수입량']\n",
        "    # 해당 농작물 가격 (index == 12)\n",
        "    crops_price = df['가격']\n",
        "    # 경유 가격\n",
        "    diesel_price = df['경유가격']\n",
        "    # 물가지수(price index -> pidx), 2015년 기준 얼마나 오르고 내렸는지\n",
        "    total_pidx = df['총물가지수']\n",
        "    prod_pidx = df['상품']\n",
        "    agricul_marine_prod_pidx = df['농축수산물']\n",
        "    indust_prod_pidx = df['공업제품']\n",
        "    serv_pidx = df['서비스']\n",
        "    pub_serv_pidx = df['공공서비스']\n",
        "    per_serv_pidx = df['개인서비스']\n",
        "    house_pidx = df['집세']\n",
        "\n",
        "    # 정규화 해야하는 데이터셋\n",
        "    prams = [precipi_avg, precipi_max,             # 강수량\n",
        "            temper_avg, temper_max, temper_min,    # 기온\n",
        "            windSpeed_avg, windSpeed_max,          # 풍속\n",
        "            humidity_avg, humidity_min,            # 습도\n",
        "            sunshine,                              # 일조량\n",
        "            insolation,                            # 일사량\n",
        "            crops_price,                           # 해당 농작물 월별 가격\n",
        "            diesel_price,                          # 월별 경유 가격\n",
        "            last_amount_import,                    # 전년 수입량\n",
        "            # 물가지수\n",
        "            total_pidx, prod_pidx, agricul_marine_prod_pidx, indust_prod_pidx, serv_pidx, pub_serv_pidx, per_serv_pidx, house_pidx,\n",
        "            ]\n",
        "\n",
        "    dataset.append(prams)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAjjwEt-14I4"
      },
      "source": [
        "##### Predicted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "805kUK3l16f1"
      },
      "source": [
        "CROPS = 'onion'\n",
        "pred_dataset = []\n",
        "\n",
        "# 지난 최대 5년간 최대, 최소치를 기준으로 정규화해야 하는 항목들\n",
        "df = pd.read_csv('./Dataset/'+CROPS+'/last_production_'+CROPS+'.csv', index_col=0, encoding='cp949')\n",
        "# 전년 재배면적\n",
        "last_cultiv_area = df['전년면적']\n",
        "# 전년 평균 생산량(수확량)\n",
        "last_production = df['전년생산량']\n",
        "# 전년 평균 생산단수\n",
        "last_prod_unit = df['전년단수']\n",
        "pred_last_prams = [last_cultiv_area,                    # 전년 재배면적\n",
        "            last_production,                       # 전년 평균 생산량\n",
        "            last_prod_unit                         # 전년 평균 생산단수\n",
        "            ]\n",
        "\n",
        "f_name = str(TARGET_YEAR)+'_'+CROPS+'.csv'\n",
        "df = pd.read_csv('./Dataset/'+CROPS+'/'+f_name, index_col=0)\n",
        "\n",
        "''' 기상변수 '''\n",
        "# 강수량\n",
        "precipi_avg = df['평균월강수량(mm)']\n",
        "precipi_max = df['최다월강수량(mm)']\n",
        "# 기온\n",
        "temper_avg = df['평균기온(℃)']\n",
        "temper_max = df['평균최고기온(℃)']\n",
        "temper_min = df['평균최저기온(℃)']\n",
        "# 풍속\n",
        "windSpeed_avg = df['평균풍속(m/s)']\n",
        "windSpeed_max = df['최대풍속(m/s)']\n",
        "# 습도\n",
        "humidity_avg = df['평균습도(%rh)']\n",
        "humidity_min = df['최저습도(%rh)']\n",
        "# 일조량 / 일사량\n",
        "sunshine = df['일조합']\n",
        "insolation = df['일사합']\n",
        "\n",
        "''' 기타변수 '''\n",
        "# 전년 수입량\n",
        "last_amount_import = df['전년수입량']\n",
        "# 해당 농작물 가격 (index == 12)\n",
        "crops_price = df['가격']\n",
        "# 경유 가격\n",
        "diesel_price = df['경유가격']\n",
        "# 물가지수(price index -> pidx), 2015년 기준 얼마나 오르고 내렸는지\n",
        "total_pidx = df['총물가지수']\n",
        "prod_pidx = df['상품']\n",
        "agricul_marine_prod_pidx = df['농축수산물']\n",
        "indust_prod_pidx = df['공업제품']\n",
        "serv_pidx = df['서비스']\n",
        "pub_serv_pidx = df['공공서비스']\n",
        "per_serv_pidx = df['개인서비스']\n",
        "house_pidx = df['집세']\n",
        "\n",
        "# 정규화 해야하는 데이터셋\n",
        "pred_prams = [precipi_avg, precipi_max,             # 강수량\n",
        "        temper_avg, temper_max, temper_min,    # 기온\n",
        "        windSpeed_avg, windSpeed_max,          # 풍속\n",
        "        humidity_avg, humidity_min,            # 습도\n",
        "        sunshine,                              # 일조량\n",
        "        insolation,                            # 일사량\n",
        "        crops_price,                           # 해당 농작물 월별 가격\n",
        "        diesel_price,                          # 월별 경유 가격\n",
        "        last_amount_import,                    # 전년 수입량\n",
        "        # 물가지수\n",
        "        total_pidx, prod_pidx, agricul_marine_prod_pidx, indust_prod_pidx, serv_pidx, pub_serv_pidx, per_serv_pidx, house_pidx,\n",
        "        ]\n",
        "\n",
        "pred_dataset.append(pred_prams)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtnE8nF3927h"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg-adhTJ1eVD"
      },
      "source": [
        "##### Trained data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4aVA0E97aI"
      },
      "source": [
        "''' 정규화 '''\n",
        "scaler = MinMaxScaler()\n",
        "# last_prams\n",
        "norm_last = []\n",
        "for idx, pram in enumerate(last_prams) :\n",
        "    tmp_last = []\n",
        "    for next in range(0, (END_YEAR-START_YEAR)+1) :\n",
        "        tmp_df = pram\n",
        "\n",
        "        cur_year = START_YEAR + next\n",
        "        year_list = tmp_df.index.values.tolist()\n",
        "        if cur_year-4 < year_list[-1] : year_list = year_list[year_list.index(cur_year):len(year_list)] # 5년간 데이터가 없을 경우\n",
        "        else : year_list = year_list[year_list.index(cur_year):year_list.index(cur_year-4)+1]           # 5년간 데이터가 있는 경우\n",
        "\n",
        "        tmp_df = tmp_df.loc[year_list]\n",
        "        tmp_last.append(Normalization(tmp_df).to_numpy()[0])\n",
        "    norm_last.append(tmp_last)\n",
        "\n",
        "# prams\n",
        "for idx, data in enumerate(dataset) :\n",
        "    for i, pram in enumerate(data) :\n",
        "        pram = Normalization(pram)\n",
        "        pram = pram.to_numpy()\n",
        "\n",
        "        dataset[idx][i] = pram\n",
        "\n",
        "''' 데이터셋 구축 '''\n",
        "X_dataset = []\n",
        "y_dataset = []\n",
        "\n",
        "# X, y 데이터셋 구분\n",
        "for cur, year in enumerate(dataset) :\n",
        "    tmp_X1 = [[], [], [], [], []] # 1~5월\n",
        "    tmp_y1 = [] # 6월\n",
        "    tmp_X2 = [[], [], [], [] ,[]] # 7~11월\n",
        "    tmp_y2 = [] # 12월\n",
        "    for idx, data in enumerate(year) :\n",
        "        for month in range(0, 12) :\n",
        "            if idx == 12 : \n",
        "                if month == 5 : tmp_y1.append(data[month])\n",
        "                elif month == 11: tmp_y2.append(data[month])\n",
        "            else :\n",
        "                if month < 5 : tmp_X1[month].append(data[month])\n",
        "                elif month > 5 and month < 11 : tmp_X2[month-6].append(data[month])\n",
        "\n",
        "    for last_data in norm_last :\n",
        "        for month in tmp_X1 : month.append(last_data[cur])\n",
        "        for month in tmp_X2 : month.append(last_data[cur])\n",
        "    \n",
        "    X_dataset.append(tmp_X1)\n",
        "    y_dataset.append(tmp_y1)\n",
        "    X_dataset.append(tmp_X2)\n",
        "    y_dataset.append(tmp_y2)\n",
        "\n",
        "# 데이터 형변환\n",
        "X_dataset = np.array(X_dataset)\n",
        "y_dataset = np.array(y_dataset)\n",
        "\n",
        "# reshape X_dataset\n",
        "X_dataset = X_dataset.reshape(X_dataset.shape[0], X_dataset.shape[1] * X_dataset.shape[2], 1)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlE6df411ic1"
      },
      "source": [
        "##### Predicted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4jIkHaQ1ph3"
      },
      "source": [
        "''' 정규화 '''\n",
        "# last_prams\n",
        "norm_last = []\n",
        "for idx, pram in enumerate(pred_last_prams) :\n",
        "    tmp_last = []\n",
        "    tmp_df = pram\n",
        "\n",
        "    year_list = pram.index.values.tolist()\n",
        "    if TARGET_YEAR-4 < year_list[-1] : year_list = year_list[year_list.index(TARGET_YEAR):len(year_list)] # 5년간 데이터가 없을 경우\n",
        "    else : year_list = year_list[year_list.index(TARGET_YEAR):year_list.index(TARGET_YEAR-4)+1]           # 5년간 데이터가 있는 경우\n",
        "\n",
        "    tmp_df = tmp_df.loc[year_list]\n",
        "    tmp_last.append(Normalization(tmp_df).to_numpy()[0])\n",
        "    norm_last.append(tmp_last)\n",
        "\n",
        "# prams\n",
        "for idx, data in enumerate(pred_dataset) :\n",
        "    for i, pram in enumerate(data) :\n",
        "        pram = Normalization(pram)\n",
        "        pram = pram.to_numpy()\n",
        "\n",
        "        pred_dataset[idx][i] = pram\n",
        "\n",
        "''' 데이터셋 구축 '''\n",
        "pred_X_dataset = []\n",
        "pred_y_dataset = []\n",
        "\n",
        "# X, y 데이터셋 구분\n",
        "for cur, year in enumerate(pred_dataset) :\n",
        "    tmp_X1 = [[], [], [], [], []] # 1~5월\n",
        "    tmp_y1 = [] # 6월\n",
        "    tmp_X2 = [[], [], [], [] ,[]] # 7~11월\n",
        "    tmp_y2 = [] # 12월\n",
        "    for idx, data in enumerate(year) :\n",
        "        for month in range(0, 12) :\n",
        "            if idx == 12 : \n",
        "                if month == 5 : tmp_y1.append(data[month])\n",
        "                elif month == 11: tmp_y2.append(data[month])\n",
        "            else :\n",
        "                if month < 5 : tmp_X1[month].append(data[month])\n",
        "                elif month > 5 and month < 11 : tmp_X2[month-6].append(data[month])\n",
        "\n",
        "    for last_data in norm_last :\n",
        "        for month in tmp_X1 : month.append(last_data[cur])\n",
        "        for month in tmp_X2 : month.append(last_data[cur])\n",
        "    \n",
        "    pred_X_dataset.append(tmp_X1)\n",
        "    pred_y_dataset.append(tmp_y1)\n",
        "    pred_X_dataset.append(tmp_X2)\n",
        "    pred_y_dataset.append(tmp_y2)\n",
        "\n",
        "# 데이터 형변환\n",
        "pred_X_dataset = np.array(pred_X_dataset)\n",
        "pred_y_dataset = np.array(pred_y_dataset)\n",
        "\n",
        "# reshape X_dataset\n",
        "pred_X_dataset = pred_X_dataset.reshape(pred_X_dataset.shape[0], pred_X_dataset.shape[1] * pred_X_dataset.shape[2], 1)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p-DWnxJsVXf"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyig-hprrz8E",
        "outputId": "5cb1c611-8734-49d5-8ff5-f250abebbcaf"
      },
      "source": [
        "# Data division (Train : Test = 9 : 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.1)\n",
        "print(\"########## Train + Test (X,) (y,) / Test (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# Data division (Train : Validation = 8 : 2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "print(\"########## Train (X,) (y,) / Validation (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Train + Test (X,) (y,) / Test (X,) (y,) ##########\n",
            "(25, 120, 1) (25, 1) (3, 120, 1) (3, 1)\n",
            "########## Train (X,) (y,) / Validation (X,) (y,) ##########\n",
            "(20, 120, 1) (20, 1) (5, 120, 1) (5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P4ubOMj-YWG"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GpM_MnL-Ydz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ab04c-574b-446e-9362-d22736d99278"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(64,                    # 해당 층의 노드 개수\n",
        "                       input_shape=(20, 120, 1),    # input_shape=?\n",
        "                       return_sequences=True)))     # return_sequences == 각 시퀀스를 출력할지\n",
        "model.add(Dropout(0.01))                            # 과적합 방지용 Ex. Dropout 20%(==0.2)\n",
        "model.add(Bidirectional(LSTM(16)))\n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.build(input_shape=(20, 120, 1))\n",
        "model.compile(loss=losses.MeanSquaredError(),\n",
        "              optimizer=Adam(learning_rate=0.000025), # pram ex. learning_rate=0.0001\n",
        "              metrics=[metrics.MeanSquaredError()]\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_82 (Bidirecti  (20, 120, 128)           33792     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (20, 120, 128)            0         \n",
            "                                                                 \n",
            " bidirectional_83 (Bidirecti  (20, 32)                 18560     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (20, 32)                  0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (20, 1)                   33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,385\n",
            "Trainable params: 52,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQKnA-yk-bs5"
      },
      "source": [
        "### Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgorD0U-bLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88660a40-414c-4ee0-8186-e41cf2e77e37"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data = (X_val, y_val),\n",
        "                    batch_size = 24,                    # Train set's 1~2%\n",
        "                    epochs = 408,                       # Train set's 10%\n",
        "                    verbose = 1,                        # 0=silent, 1=progress bar, 2=one line per epoch.\n",
        "                    )\n",
        "\n",
        "# loss and acc graph (train nd val)\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[[\"loss\", \"val_loss\"]].plot()\n",
        "\n",
        "# Acc and Loss about real data\n",
        "learning_lost, learning_err = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(\"Learning error % :\", learning_err * 100)\n",
        "print(\"Learning loss % :\", learning_lost * 100)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/408\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 2/408\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 3/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 4/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 5/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 6/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 7/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 8/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 9/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 10/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 11/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 12/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 13/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4497 - mean_squared_error: 0.4497 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 14/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 15/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 16/408\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 17/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 18/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 19/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 20/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 21/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 22/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 23/408\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 24/408\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 25/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 26/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 27/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 28/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 29/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 30/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 31/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 32/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 33/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 34/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 35/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 36/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 37/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 38/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 39/408\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 40/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 41/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 42/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 43/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 44/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 45/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 46/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 47/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 48/408\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 49/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 50/408\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 51/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 52/408\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 53/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 54/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 55/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 56/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 57/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 58/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 59/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 60/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 61/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 62/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 63/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 64/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 65/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 66/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 67/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 68/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 69/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 70/408\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 71/408\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 72/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 73/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 74/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 75/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 76/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 77/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4499 - mean_squared_error: 0.4499 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 78/408\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 79/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 80/408\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 81/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 82/408\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 83/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 84/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 85/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4500 - mean_squared_error: 0.4500 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 86/408\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 87/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 88/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 89/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4499 - mean_squared_error: 0.4499 - val_loss: 0.5974 - val_mean_squared_error: 0.5974\n",
            "Epoch 90/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4496 - mean_squared_error: 0.4496 - val_loss: 0.5971 - val_mean_squared_error: 0.5971\n",
            "Epoch 91/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4486 - mean_squared_error: 0.4486 - val_loss: 0.5960 - val_mean_squared_error: 0.5960\n",
            "Epoch 92/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4488 - mean_squared_error: 0.4488 - val_loss: 0.5948 - val_mean_squared_error: 0.5948\n",
            "Epoch 93/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4466 - mean_squared_error: 0.4466 - val_loss: 0.5936 - val_mean_squared_error: 0.5936\n",
            "Epoch 94/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4463 - mean_squared_error: 0.4463 - val_loss: 0.5915 - val_mean_squared_error: 0.5915\n",
            "Epoch 95/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4458 - mean_squared_error: 0.4458 - val_loss: 0.5891 - val_mean_squared_error: 0.5891\n",
            "Epoch 96/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4417 - mean_squared_error: 0.4417 - val_loss: 0.5867 - val_mean_squared_error: 0.5867\n",
            "Epoch 97/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4398 - mean_squared_error: 0.4398 - val_loss: 0.5841 - val_mean_squared_error: 0.5841\n",
            "Epoch 98/408\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.4391 - mean_squared_error: 0.4391 - val_loss: 0.5816 - val_mean_squared_error: 0.5816\n",
            "Epoch 99/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4368 - mean_squared_error: 0.4368 - val_loss: 0.5790 - val_mean_squared_error: 0.5790\n",
            "Epoch 100/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.4359 - mean_squared_error: 0.4359 - val_loss: 0.5750 - val_mean_squared_error: 0.5750\n",
            "Epoch 101/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4324 - mean_squared_error: 0.4324 - val_loss: 0.5696 - val_mean_squared_error: 0.5696\n",
            "Epoch 102/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4289 - mean_squared_error: 0.4289 - val_loss: 0.5629 - val_mean_squared_error: 0.5629\n",
            "Epoch 103/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.4227 - mean_squared_error: 0.4227 - val_loss: 0.5563 - val_mean_squared_error: 0.5563\n",
            "Epoch 104/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4207 - mean_squared_error: 0.4207 - val_loss: 0.5496 - val_mean_squared_error: 0.5496\n",
            "Epoch 105/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4140 - mean_squared_error: 0.4140 - val_loss: 0.5428 - val_mean_squared_error: 0.5428\n",
            "Epoch 106/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4079 - mean_squared_error: 0.4079 - val_loss: 0.5360 - val_mean_squared_error: 0.5360\n",
            "Epoch 107/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4028 - mean_squared_error: 0.4028 - val_loss: 0.5292 - val_mean_squared_error: 0.5292\n",
            "Epoch 108/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4008 - mean_squared_error: 0.4008 - val_loss: 0.5225 - val_mean_squared_error: 0.5225\n",
            "Epoch 109/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3944 - mean_squared_error: 0.3944 - val_loss: 0.5157 - val_mean_squared_error: 0.5157\n",
            "Epoch 110/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3893 - mean_squared_error: 0.3893 - val_loss: 0.5090 - val_mean_squared_error: 0.5090\n",
            "Epoch 111/408\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3853 - mean_squared_error: 0.3853 - val_loss: 0.5024 - val_mean_squared_error: 0.5024\n",
            "Epoch 112/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3769 - mean_squared_error: 0.3769 - val_loss: 0.4958 - val_mean_squared_error: 0.4958\n",
            "Epoch 113/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.4893 - val_mean_squared_error: 0.4893\n",
            "Epoch 114/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3735 - mean_squared_error: 0.3735 - val_loss: 0.4829 - val_mean_squared_error: 0.4829\n",
            "Epoch 115/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3698 - mean_squared_error: 0.3698 - val_loss: 0.4765 - val_mean_squared_error: 0.4765\n",
            "Epoch 116/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3668 - mean_squared_error: 0.3668 - val_loss: 0.4703 - val_mean_squared_error: 0.4703\n",
            "Epoch 117/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3567 - mean_squared_error: 0.3567 - val_loss: 0.4641 - val_mean_squared_error: 0.4641\n",
            "Epoch 118/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3549 - mean_squared_error: 0.3549 - val_loss: 0.4580 - val_mean_squared_error: 0.4580\n",
            "Epoch 119/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.4521 - val_mean_squared_error: 0.4521\n",
            "Epoch 120/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3415 - mean_squared_error: 0.3415 - val_loss: 0.4462 - val_mean_squared_error: 0.4462\n",
            "Epoch 121/408\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3399 - mean_squared_error: 0.3399 - val_loss: 0.4403 - val_mean_squared_error: 0.4403\n",
            "Epoch 122/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3377 - mean_squared_error: 0.3377 - val_loss: 0.4346 - val_mean_squared_error: 0.4346\n",
            "Epoch 123/408\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.4290 - val_mean_squared_error: 0.4290\n",
            "Epoch 124/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.4234 - val_mean_squared_error: 0.4234\n",
            "Epoch 125/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.3242 - mean_squared_error: 0.3242 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
            "Epoch 126/408\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.4126 - val_mean_squared_error: 0.4126\n",
            "Epoch 127/408\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.3192 - mean_squared_error: 0.3192 - val_loss: 0.4072 - val_mean_squared_error: 0.4072\n",
            "Epoch 128/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3125 - mean_squared_error: 0.3125 - val_loss: 0.4020 - val_mean_squared_error: 0.4020\n",
            "Epoch 129/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 0.3969 - val_mean_squared_error: 0.3969\n",
            "Epoch 130/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3065 - mean_squared_error: 0.3065 - val_loss: 0.3918 - val_mean_squared_error: 0.3918\n",
            "Epoch 131/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3029 - mean_squared_error: 0.3029 - val_loss: 0.3868 - val_mean_squared_error: 0.3868\n",
            "Epoch 132/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2993 - mean_squared_error: 0.2993 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
            "Epoch 133/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2948 - mean_squared_error: 0.2948 - val_loss: 0.3770 - val_mean_squared_error: 0.3770\n",
            "Epoch 134/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2906 - mean_squared_error: 0.2906 - val_loss: 0.3722 - val_mean_squared_error: 0.3722\n",
            "Epoch 135/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2917 - mean_squared_error: 0.2917 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
            "Epoch 136/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.2870 - mean_squared_error: 0.2870 - val_loss: 0.3628 - val_mean_squared_error: 0.3628\n",
            "Epoch 137/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2888 - mean_squared_error: 0.2888 - val_loss: 0.3581 - val_mean_squared_error: 0.3581\n",
            "Epoch 138/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2835 - mean_squared_error: 0.2835 - val_loss: 0.3536 - val_mean_squared_error: 0.3536\n",
            "Epoch 139/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2781 - mean_squared_error: 0.2781 - val_loss: 0.3491 - val_mean_squared_error: 0.3491\n",
            "Epoch 140/408\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.2767 - mean_squared_error: 0.2767 - val_loss: 0.3447 - val_mean_squared_error: 0.3447\n",
            "Epoch 141/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2720 - mean_squared_error: 0.2720 - val_loss: 0.3403 - val_mean_squared_error: 0.3403\n",
            "Epoch 142/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2729 - mean_squared_error: 0.2729 - val_loss: 0.3360 - val_mean_squared_error: 0.3360\n",
            "Epoch 143/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2683 - mean_squared_error: 0.2683 - val_loss: 0.3317 - val_mean_squared_error: 0.3317\n",
            "Epoch 144/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2641 - mean_squared_error: 0.2641 - val_loss: 0.3275 - val_mean_squared_error: 0.3275\n",
            "Epoch 145/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2659 - mean_squared_error: 0.2659 - val_loss: 0.3233 - val_mean_squared_error: 0.3233\n",
            "Epoch 146/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2583 - mean_squared_error: 0.2583 - val_loss: 0.3192 - val_mean_squared_error: 0.3192\n",
            "Epoch 147/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2607 - mean_squared_error: 0.2607 - val_loss: 0.3151 - val_mean_squared_error: 0.3151\n",
            "Epoch 148/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2564 - mean_squared_error: 0.2564 - val_loss: 0.3111 - val_mean_squared_error: 0.3111\n",
            "Epoch 149/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.2571 - mean_squared_error: 0.2571 - val_loss: 0.3072 - val_mean_squared_error: 0.3072\n",
            "Epoch 150/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2494 - mean_squared_error: 0.2494 - val_loss: 0.3032 - val_mean_squared_error: 0.3032\n",
            "Epoch 151/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2479 - mean_squared_error: 0.2479 - val_loss: 0.2994 - val_mean_squared_error: 0.2994\n",
            "Epoch 152/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2478 - mean_squared_error: 0.2478 - val_loss: 0.2955 - val_mean_squared_error: 0.2955\n",
            "Epoch 153/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2488 - mean_squared_error: 0.2488 - val_loss: 0.2918 - val_mean_squared_error: 0.2918\n",
            "Epoch 154/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2447 - mean_squared_error: 0.2447 - val_loss: 0.2880 - val_mean_squared_error: 0.2880\n",
            "Epoch 155/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.2386 - mean_squared_error: 0.2386 - val_loss: 0.2843 - val_mean_squared_error: 0.2843\n",
            "Epoch 156/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2406 - mean_squared_error: 0.2406 - val_loss: 0.2807 - val_mean_squared_error: 0.2807\n",
            "Epoch 157/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2431 - mean_squared_error: 0.2431 - val_loss: 0.2771 - val_mean_squared_error: 0.2771\n",
            "Epoch 158/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2351 - mean_squared_error: 0.2351 - val_loss: 0.2736 - val_mean_squared_error: 0.2736\n",
            "Epoch 159/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2305 - mean_squared_error: 0.2305 - val_loss: 0.2700 - val_mean_squared_error: 0.2700\n",
            "Epoch 160/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2305 - mean_squared_error: 0.2305 - val_loss: 0.2666 - val_mean_squared_error: 0.2666\n",
            "Epoch 161/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.2287 - mean_squared_error: 0.2287 - val_loss: 0.2631 - val_mean_squared_error: 0.2631\n",
            "Epoch 162/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2253 - mean_squared_error: 0.2253 - val_loss: 0.2597 - val_mean_squared_error: 0.2597\n",
            "Epoch 163/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2248 - mean_squared_error: 0.2248 - val_loss: 0.2564 - val_mean_squared_error: 0.2564\n",
            "Epoch 164/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2302 - mean_squared_error: 0.2302 - val_loss: 0.2530 - val_mean_squared_error: 0.2530\n",
            "Epoch 165/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2232 - mean_squared_error: 0.2232 - val_loss: 0.2498 - val_mean_squared_error: 0.2498\n",
            "Epoch 166/408\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.2219 - mean_squared_error: 0.2219 - val_loss: 0.2465 - val_mean_squared_error: 0.2465\n",
            "Epoch 167/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2201 - mean_squared_error: 0.2201 - val_loss: 0.2433 - val_mean_squared_error: 0.2433\n",
            "Epoch 168/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2142 - mean_squared_error: 0.2142 - val_loss: 0.2401 - val_mean_squared_error: 0.2401\n",
            "Epoch 169/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2112 - mean_squared_error: 0.2112 - val_loss: 0.2370 - val_mean_squared_error: 0.2370\n",
            "Epoch 170/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2117 - mean_squared_error: 0.2117 - val_loss: 0.2339 - val_mean_squared_error: 0.2339\n",
            "Epoch 171/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2121 - mean_squared_error: 0.2121 - val_loss: 0.2308 - val_mean_squared_error: 0.2308\n",
            "Epoch 172/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2167 - mean_squared_error: 0.2167 - val_loss: 0.2278 - val_mean_squared_error: 0.2278\n",
            "Epoch 173/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.2073 - mean_squared_error: 0.2073 - val_loss: 0.2248 - val_mean_squared_error: 0.2248\n",
            "Epoch 174/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.2066 - mean_squared_error: 0.2066 - val_loss: 0.2219 - val_mean_squared_error: 0.2219\n",
            "Epoch 175/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.2067 - mean_squared_error: 0.2067 - val_loss: 0.2190 - val_mean_squared_error: 0.2190\n",
            "Epoch 176/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2006 - mean_squared_error: 0.2006 - val_loss: 0.2161 - val_mean_squared_error: 0.2161\n",
            "Epoch 177/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.2059 - mean_squared_error: 0.2059 - val_loss: 0.2133 - val_mean_squared_error: 0.2133\n",
            "Epoch 178/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2019 - mean_squared_error: 0.2019 - val_loss: 0.2105 - val_mean_squared_error: 0.2105\n",
            "Epoch 179/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.2005 - mean_squared_error: 0.2005 - val_loss: 0.2077 - val_mean_squared_error: 0.2077\n",
            "Epoch 180/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2020 - mean_squared_error: 0.2020 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
            "Epoch 181/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1978 - mean_squared_error: 0.1978 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
            "Epoch 182/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1956 - mean_squared_error: 0.1956 - val_loss: 0.1997 - val_mean_squared_error: 0.1997\n",
            "Epoch 183/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1974 - mean_squared_error: 0.1974 - val_loss: 0.1971 - val_mean_squared_error: 0.1971\n",
            "Epoch 184/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1948 - mean_squared_error: 0.1948 - val_loss: 0.1945 - val_mean_squared_error: 0.1945\n",
            "Epoch 185/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1955 - mean_squared_error: 0.1955 - val_loss: 0.1920 - val_mean_squared_error: 0.1920\n",
            "Epoch 186/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1921 - mean_squared_error: 0.1921 - val_loss: 0.1895 - val_mean_squared_error: 0.1895\n",
            "Epoch 187/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1955 - mean_squared_error: 0.1955 - val_loss: 0.1870 - val_mean_squared_error: 0.1870\n",
            "Epoch 188/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1879 - mean_squared_error: 0.1879 - val_loss: 0.1846 - val_mean_squared_error: 0.1846\n",
            "Epoch 189/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1920 - mean_squared_error: 0.1920 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
            "Epoch 190/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1889 - mean_squared_error: 0.1889 - val_loss: 0.1799 - val_mean_squared_error: 0.1799\n",
            "Epoch 191/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1857 - mean_squared_error: 0.1857 - val_loss: 0.1777 - val_mean_squared_error: 0.1777\n",
            "Epoch 192/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1884 - mean_squared_error: 0.1884 - val_loss: 0.1754 - val_mean_squared_error: 0.1754\n",
            "Epoch 193/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1852 - mean_squared_error: 0.1852 - val_loss: 0.1732 - val_mean_squared_error: 0.1732\n",
            "Epoch 194/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1857 - mean_squared_error: 0.1857 - val_loss: 0.1710 - val_mean_squared_error: 0.1710\n",
            "Epoch 195/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1858 - mean_squared_error: 0.1858 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
            "Epoch 196/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1842 - mean_squared_error: 0.1842 - val_loss: 0.1668 - val_mean_squared_error: 0.1668\n",
            "Epoch 197/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1835 - mean_squared_error: 0.1835 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
            "Epoch 198/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1835 - mean_squared_error: 0.1835 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
            "Epoch 199/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1795 - mean_squared_error: 0.1795 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
            "Epoch 200/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1816 - mean_squared_error: 0.1816 - val_loss: 0.1589 - val_mean_squared_error: 0.1589\n",
            "Epoch 201/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1849 - mean_squared_error: 0.1849 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
            "Epoch 202/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1837 - mean_squared_error: 0.1837 - val_loss: 0.1551 - val_mean_squared_error: 0.1551\n",
            "Epoch 203/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1790 - mean_squared_error: 0.1790 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
            "Epoch 204/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1797 - mean_squared_error: 0.1797 - val_loss: 0.1515 - val_mean_squared_error: 0.1515\n",
            "Epoch 205/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1801 - mean_squared_error: 0.1801 - val_loss: 0.1498 - val_mean_squared_error: 0.1498\n",
            "Epoch 206/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1791 - mean_squared_error: 0.1791 - val_loss: 0.1481 - val_mean_squared_error: 0.1481\n",
            "Epoch 207/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1804 - mean_squared_error: 0.1804 - val_loss: 0.1465 - val_mean_squared_error: 0.1465\n",
            "Epoch 208/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1787 - mean_squared_error: 0.1787 - val_loss: 0.1448 - val_mean_squared_error: 0.1448\n",
            "Epoch 209/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1778 - mean_squared_error: 0.1778 - val_loss: 0.1433 - val_mean_squared_error: 0.1433\n",
            "Epoch 210/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1742 - mean_squared_error: 0.1742 - val_loss: 0.1417 - val_mean_squared_error: 0.1417\n",
            "Epoch 211/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1794 - mean_squared_error: 0.1794 - val_loss: 0.1402 - val_mean_squared_error: 0.1402\n",
            "Epoch 212/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1800 - mean_squared_error: 0.1800 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
            "Epoch 213/408\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.1373 - val_mean_squared_error: 0.1373\n",
            "Epoch 214/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1359 - val_mean_squared_error: 0.1359\n",
            "Epoch 215/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1693 - mean_squared_error: 0.1693 - val_loss: 0.1345 - val_mean_squared_error: 0.1345\n",
            "Epoch 216/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1715 - mean_squared_error: 0.1715 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
            "Epoch 217/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1805 - mean_squared_error: 0.1805 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 218/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1756 - mean_squared_error: 0.1756 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
            "Epoch 219/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1813 - mean_squared_error: 0.1813 - val_loss: 0.1293 - val_mean_squared_error: 0.1293\n",
            "Epoch 220/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1810 - mean_squared_error: 0.1810 - val_loss: 0.1281 - val_mean_squared_error: 0.1281\n",
            "Epoch 221/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1698 - mean_squared_error: 0.1698 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
            "Epoch 222/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1739 - mean_squared_error: 0.1739 - val_loss: 0.1259 - val_mean_squared_error: 0.1259\n",
            "Epoch 223/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1678 - mean_squared_error: 0.1678 - val_loss: 0.1248 - val_mean_squared_error: 0.1248\n",
            "Epoch 224/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1677 - mean_squared_error: 0.1677 - val_loss: 0.1237 - val_mean_squared_error: 0.1237\n",
            "Epoch 225/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1708 - mean_squared_error: 0.1708 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
            "Epoch 226/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1725 - mean_squared_error: 0.1725 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
            "Epoch 227/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1714 - mean_squared_error: 0.1714 - val_loss: 0.1208 - val_mean_squared_error: 0.1208\n",
            "Epoch 228/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1727 - mean_squared_error: 0.1727 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
            "Epoch 229/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1742 - mean_squared_error: 0.1742 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
            "Epoch 230/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1716 - mean_squared_error: 0.1716 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
            "Epoch 231/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1693 - mean_squared_error: 0.1693 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
            "Epoch 232/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1761 - mean_squared_error: 0.1761 - val_loss: 0.1166 - val_mean_squared_error: 0.1166\n",
            "Epoch 233/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1702 - mean_squared_error: 0.1702 - val_loss: 0.1159 - val_mean_squared_error: 0.1159\n",
            "Epoch 234/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1715 - mean_squared_error: 0.1715 - val_loss: 0.1152 - val_mean_squared_error: 0.1152\n",
            "Epoch 235/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1624 - mean_squared_error: 0.1624 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
            "Epoch 236/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1720 - mean_squared_error: 0.1720 - val_loss: 0.1138 - val_mean_squared_error: 0.1138\n",
            "Epoch 237/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1758 - mean_squared_error: 0.1758 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
            "Epoch 238/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1697 - mean_squared_error: 0.1697 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
            "Epoch 239/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1671 - mean_squared_error: 0.1671 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
            "Epoch 240/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1746 - mean_squared_error: 0.1746 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
            "Epoch 241/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1683 - mean_squared_error: 0.1683 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
            "Epoch 242/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1731 - mean_squared_error: 0.1731 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
            "Epoch 243/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1703 - mean_squared_error: 0.1703 - val_loss: 0.1099 - val_mean_squared_error: 0.1099\n",
            "Epoch 244/408\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1735 - mean_squared_error: 0.1735 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
            "Epoch 245/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1696 - mean_squared_error: 0.1696 - val_loss: 0.1090 - val_mean_squared_error: 0.1090\n",
            "Epoch 246/408\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1677 - mean_squared_error: 0.1677 - val_loss: 0.1085 - val_mean_squared_error: 0.1085\n",
            "Epoch 247/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1692 - mean_squared_error: 0.1692 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
            "Epoch 248/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
            "Epoch 249/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1684 - mean_squared_error: 0.1684 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
            "Epoch 250/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
            "Epoch 251/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1676 - mean_squared_error: 0.1676 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
            "Epoch 252/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1704 - mean_squared_error: 0.1704 - val_loss: 0.1063 - val_mean_squared_error: 0.1063\n",
            "Epoch 253/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1708 - mean_squared_error: 0.1708 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
            "Epoch 254/408\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1712 - mean_squared_error: 0.1712 - val_loss: 0.1057 - val_mean_squared_error: 0.1057\n",
            "Epoch 255/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1678 - mean_squared_error: 0.1678 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
            "Epoch 256/408\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1666 - mean_squared_error: 0.1666 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
            "Epoch 257/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1748 - mean_squared_error: 0.1748 - val_loss: 0.1050 - val_mean_squared_error: 0.1050\n",
            "Epoch 258/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1656 - mean_squared_error: 0.1656 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
            "Epoch 259/408\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.1700 - mean_squared_error: 0.1700 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
            "Epoch 260/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1676 - mean_squared_error: 0.1676 - val_loss: 0.1044 - val_mean_squared_error: 0.1044\n",
            "Epoch 261/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1680 - mean_squared_error: 0.1680 - val_loss: 0.1042 - val_mean_squared_error: 0.1042\n",
            "Epoch 262/408\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1687 - mean_squared_error: 0.1687 - val_loss: 0.1041 - val_mean_squared_error: 0.1041\n",
            "Epoch 263/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1694 - mean_squared_error: 0.1694 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
            "Epoch 264/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
            "Epoch 265/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1695 - mean_squared_error: 0.1695 - val_loss: 0.1037 - val_mean_squared_error: 0.1037\n",
            "Epoch 266/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1777 - mean_squared_error: 0.1777 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
            "Epoch 267/408\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1754 - mean_squared_error: 0.1754 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
            "Epoch 268/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1704 - mean_squared_error: 0.1704 - val_loss: 0.1034 - val_mean_squared_error: 0.1034\n",
            "Epoch 269/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1707 - mean_squared_error: 0.1707 - val_loss: 0.1033 - val_mean_squared_error: 0.1033\n",
            "Epoch 270/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1622 - mean_squared_error: 0.1622 - val_loss: 0.1033 - val_mean_squared_error: 0.1033\n",
            "Epoch 271/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1695 - mean_squared_error: 0.1695 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
            "Epoch 272/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1660 - mean_squared_error: 0.1660 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 273/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1687 - mean_squared_error: 0.1687 - val_loss: 0.1030 - val_mean_squared_error: 0.1030\n",
            "Epoch 274/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1030 - val_mean_squared_error: 0.1030\n",
            "Epoch 275/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1672 - mean_squared_error: 0.1672 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
            "Epoch 276/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1670 - mean_squared_error: 0.1670 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
            "Epoch 277/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1676 - mean_squared_error: 0.1676 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
            "Epoch 278/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1665 - mean_squared_error: 0.1665 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
            "Epoch 279/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1664 - mean_squared_error: 0.1664 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
            "Epoch 280/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1686 - mean_squared_error: 0.1686 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
            "Epoch 281/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 282/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 283/408\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1711 - mean_squared_error: 0.1711 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 284/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1676 - mean_squared_error: 0.1676 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 285/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1681 - mean_squared_error: 0.1681 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 286/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 287/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 288/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1692 - mean_squared_error: 0.1692 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 289/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1695 - mean_squared_error: 0.1695 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 290/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1717 - mean_squared_error: 0.1717 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 291/408\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 292/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 293/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1641 - mean_squared_error: 0.1641 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 294/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1675 - mean_squared_error: 0.1675 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 295/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1669 - mean_squared_error: 0.1669 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 296/408\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 297/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 298/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1610 - mean_squared_error: 0.1610 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 299/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1678 - mean_squared_error: 0.1678 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 300/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 301/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1618 - mean_squared_error: 0.1618 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 302/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1571 - mean_squared_error: 0.1571 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 303/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1689 - mean_squared_error: 0.1689 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 304/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1643 - mean_squared_error: 0.1643 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 305/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1672 - mean_squared_error: 0.1672 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 306/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1632 - mean_squared_error: 0.1632 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 307/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1686 - mean_squared_error: 0.1686 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 308/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 309/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1670 - mean_squared_error: 0.1670 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 310/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1696 - mean_squared_error: 0.1696 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 311/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1711 - mean_squared_error: 0.1711 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 312/408\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1677 - mean_squared_error: 0.1677 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 313/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1735 - mean_squared_error: 0.1735 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 314/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1640 - mean_squared_error: 0.1640 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 315/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1680 - mean_squared_error: 0.1680 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 316/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1729 - mean_squared_error: 0.1729 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 317/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1558 - mean_squared_error: 0.1558 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 318/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 319/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 320/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1677 - mean_squared_error: 0.1677 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 321/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 322/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 323/408\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1665 - mean_squared_error: 0.1665 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 324/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 325/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 326/408\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.1666 - mean_squared_error: 0.1666 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 327/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1667 - mean_squared_error: 0.1667 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 328/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1592 - mean_squared_error: 0.1592 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 329/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 330/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1699 - mean_squared_error: 0.1699 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 331/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1630 - mean_squared_error: 0.1630 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 332/408\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 333/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1712 - mean_squared_error: 0.1712 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 334/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 335/408\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.1601 - mean_squared_error: 0.1601 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 336/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 337/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 338/408\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1641 - mean_squared_error: 0.1641 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 339/408\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.1631 - mean_squared_error: 0.1631 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 340/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 341/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 342/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1698 - mean_squared_error: 0.1698 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 343/408\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.1693 - mean_squared_error: 0.1693 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 344/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1631 - mean_squared_error: 0.1631 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 345/408\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 346/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1675 - mean_squared_error: 0.1675 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 347/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1619 - mean_squared_error: 0.1619 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 348/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1636 - mean_squared_error: 0.1636 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 349/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1632 - mean_squared_error: 0.1632 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 350/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1616 - mean_squared_error: 0.1616 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 351/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1631 - mean_squared_error: 0.1631 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 352/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1664 - mean_squared_error: 0.1664 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 353/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1633 - mean_squared_error: 0.1633 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 354/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1660 - mean_squared_error: 0.1660 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 355/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1672 - mean_squared_error: 0.1672 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 356/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 357/408\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1638 - mean_squared_error: 0.1638 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 358/408\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1689 - mean_squared_error: 0.1689 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 359/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1633 - mean_squared_error: 0.1633 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
            "Epoch 360/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1595 - mean_squared_error: 0.1595 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
            "Epoch 361/408\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.1643 - mean_squared_error: 0.1643 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 362/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 363/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 364/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1619 - mean_squared_error: 0.1619 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 365/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 366/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 367/408\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.1586 - mean_squared_error: 0.1586 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 368/408\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.1673 - mean_squared_error: 0.1673 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 369/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1617 - mean_squared_error: 0.1617 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 370/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1667 - mean_squared_error: 0.1667 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 371/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1568 - mean_squared_error: 0.1568 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 372/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 373/408\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.1643 - mean_squared_error: 0.1643 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 374/408\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.1576 - mean_squared_error: 0.1576 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 375/408\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.1665 - mean_squared_error: 0.1665 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 376/408\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.1590 - mean_squared_error: 0.1590 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 377/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1730 - mean_squared_error: 0.1730 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 378/408\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1591 - mean_squared_error: 0.1591 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 379/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 380/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1672 - mean_squared_error: 0.1672 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 381/408\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.1622 - mean_squared_error: 0.1622 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 382/408\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.1686 - mean_squared_error: 0.1686 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 383/408\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1631 - mean_squared_error: 0.1631 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
            "Epoch 384/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1596 - mean_squared_error: 0.1596 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 385/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1674 - mean_squared_error: 0.1674 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
            "Epoch 386/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1668 - mean_squared_error: 0.1668 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
            "Epoch 387/408\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.1625 - mean_squared_error: 0.1625 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
            "Epoch 388/408\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.1616 - mean_squared_error: 0.1616 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
            "Epoch 389/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1637 - mean_squared_error: 0.1637 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
            "Epoch 390/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1629 - mean_squared_error: 0.1629 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
            "Epoch 391/408\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.1598 - mean_squared_error: 0.1598 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
            "Epoch 392/408\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.1586 - mean_squared_error: 0.1586 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
            "Epoch 393/408\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.1030 - val_mean_squared_error: 0.1030\n",
            "Epoch 394/408\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.1717 - mean_squared_error: 0.1717 - val_loss: 0.1030 - val_mean_squared_error: 0.1030\n",
            "Epoch 395/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1615 - mean_squared_error: 0.1615 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 396/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1560 - mean_squared_error: 0.1560 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 397/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1629 - mean_squared_error: 0.1629 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 398/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1608 - mean_squared_error: 0.1608 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 399/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1685 - mean_squared_error: 0.1685 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
            "Epoch 400/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1593 - mean_squared_error: 0.1593 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
            "Epoch 401/408\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.1690 - mean_squared_error: 0.1690 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
            "Epoch 402/408\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1575 - mean_squared_error: 0.1575 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
            "Epoch 403/408\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.1638 - mean_squared_error: 0.1638 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 404/408\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.1612 - mean_squared_error: 0.1612 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 405/408\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.1616 - mean_squared_error: 0.1616 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 406/408\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.1613 - mean_squared_error: 0.1613 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 407/408\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1595 - mean_squared_error: 0.1595 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "Epoch 408/408\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.1613 - mean_squared_error: 0.1613 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
            "1/1 - 0s - loss: 0.1349 - mean_squared_error: 0.1349 - 59ms/epoch - 59ms/step\n",
            "Learning error % : 13.493995368480682\n",
            "Learning loss % : 13.493995368480682\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmw7-DI7-f2S"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJrzhLK1-hLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d33477f-6147-4e50-abe6-1c553c9e5634"
      },
      "source": [
        "pred_res = model.predict(pred_X_dataset)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(y_dataset)\n",
        "print(\"Predicted Price = \", scaler.inverse_transform(pred_res))\n",
        "print(\"Real Price = \", scaler.inverse_transform(pred_y_dataset))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Price =  [[0.47440866]\n",
            " [0.5464934 ]]\n",
            "Real Price =  [[0.18673522]\n",
            " [0.30825892]]\n"
          ]
        }
      ]
    }
  ]
}