{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict Price of Agricultural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOag4re+haKPw/HYTaUqDET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/LSTM-PPoA/blob/main/Predict_Price_of_Agricultural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUHp2QmQfL70"
      },
      "source": [
        "# 참조문헌\n",
        "## [A Prediction Model for Agricultural Products Price with LSTM Network](https://www.koreascience.or.kr/article/JAKO201809469053682.page)\n",
        "\n",
        "**신성호, 이미경, 송사광**\n",
        "\n",
        "한국과학기술정보연구원 연구데이터플랫폼센터,\n",
        "한국과학기술정보연구원 연구데이터플랫폼센터/과학기술연합대학원대학교 빅데이터과학과\n",
        "\n",
        "Sungho Shin(maximus74@kisti.re.kr), Mikyoung Lee(jerryis@kisti.re.kr),\n",
        "Sa-kwang Song(esmallj@kisti.re.kr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFNr9uiwNDj"
      },
      "source": [
        "\n",
        "---\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuQW7ij4HGQc"
      },
      "source": [
        "# 당년 농산물 가격 예측 LSTM 모델\n",
        "\n",
        "Input = 1~저번 달까지의 pram 값을 하나로 묶은 array(인스턴스)\n",
        "\n",
        "output = 당월의 해당 채소 가격\n",
        "\n",
        "layer = 원래 해당 채소 가격"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8AkO_e7n4kv"
      },
      "source": [
        "### Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imYIsQ-Qn6oB",
        "outputId": "869433a9-5804-455a-e328-7a85a3b35d97"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/DeepLearning/Project/PPoA\n",
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/DeepLearning/Project/PPoA\n",
            "total 33\n",
            "drwx------ 2 root root  4096 Nov 24 06:07  Dataset\n",
            "-rw------- 1 root root 29466 Nov 26 14:44 'Predict Price of Agricultural.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urjpqmlxb99Q"
      },
      "source": [
        "### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjLL_CiwGa2v"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import metrics, losses\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76aV88cLGCI-"
      },
      "source": [
        "### Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v5fm5afGCRQ"
      },
      "source": [
        "def Normalization(targetData) :\n",
        "    return (targetData - targetData.min()) / (targetData.max() - targetData.min())\n",
        "\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ER3CZzLmvJz"
      },
      "source": [
        "### Global variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slotXBAvmvRp"
      },
      "source": [
        "TARGET_YEAR = 2020\n",
        "START_YEAR = 0\n",
        "END_YEAR = 0\n",
        "CROPS = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbsM_WkpdNAn"
      },
      "source": [
        "### Data read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li41MIACdNGY"
      },
      "source": [
        "START_YEAR = 2006\n",
        "END_YEAR = 2020\n",
        "CROPS = 'onion'\n",
        "dataset = []\n",
        "\n",
        "# 지난 최대 5년간 최대, 최소치를 기준으로 정규화해야 하는 항목들\n",
        "df = pd.read_csv('./Dataset/last_production_'+CROPS+'.csv', index_col=0, encoding='cp949')\n",
        "# 전년 재배면적\n",
        "last_cultiv_area = df['전년면적']\n",
        "# 전년 평균 생산량(수확량)\n",
        "last_production = df['전년생산량']\n",
        "# 전년 평균 생산단수\n",
        "last_prod_unit = df['전년단수']\n",
        "last_prams = [last_cultiv_area,                    # 전년 재배면적\n",
        "            last_production,                       # 전년 평균 생산량\n",
        "            last_prod_unit                         # 전년 평균 생산단수\n",
        "            ]\n",
        "\n",
        "for next in range(0, (END_YEAR-START_YEAR)+1) :\n",
        "    cur_year = START_YEAR + next\n",
        "\n",
        "    f_name = str(cur_year)+'_'+CROPS+'.csv'\n",
        "    df = pd.read_csv('./Dataset/'+f_name, index_col=0)\n",
        "\n",
        "    ''' 기상변수 '''\n",
        "    # 강수량\n",
        "    precipi_avg = df['평균월강수량(mm)']\n",
        "    precipi_max = df['최다월강수량(mm)']\n",
        "    # 기온\n",
        "    temper_avg = df['평균기온(℃)']\n",
        "    temper_max = df['평균최고기온(℃)']\n",
        "    temper_min = df['평균최저기온(℃)']\n",
        "    # 풍속\n",
        "    windSpeed_avg = df['평균풍속(m/s)']\n",
        "    windSpeed_max = df['최대풍속(m/s)']\n",
        "    # 습도\n",
        "    humidity_avg = df['평균습도(%rh)']\n",
        "    humidity_min = df['최저습도(%rh)']\n",
        "    # 일조량 / 일사량\n",
        "    sunshine = df['일조합']\n",
        "    insolation = df['일사합']\n",
        "\n",
        "    ''' 기타변수 '''\n",
        "    # 전년 수입량\n",
        "    last_amount_import = df['전년수입량']\n",
        "    # 해당 농작물 가격 (index == 12)\n",
        "    crops_price = df['가격']\n",
        "    # 경유 가격\n",
        "    diesel_price = df['경유가격']\n",
        "    # 물가지수(price index -> pidx), 2015년 기준 얼마나 오르고 내렸는지\n",
        "    total_pidx = df['총물가지수']\n",
        "    prod_pidx = df['상품']\n",
        "    agricul_marine_prod_pidx = df['농축수산물']\n",
        "    indust_prod_pidx = df['공업제품']\n",
        "    serv_pidx = df['서비스']\n",
        "    pub_serv_pidx = df['공공서비스']\n",
        "    per_serv_pidx = df['개인서비스']\n",
        "    house_pidx = df['집세']\n",
        "\n",
        "    # 정규화 해야하는 데이터셋\n",
        "    prams = [precipi_avg, precipi_max,             # 강수량\n",
        "            temper_avg, temper_max, temper_min,    # 기온\n",
        "            windSpeed_avg, windSpeed_max,          # 풍속\n",
        "            humidity_avg, humidity_min,            # 습도\n",
        "            sunshine,                              # 일조량\n",
        "            insolation,                            # 일사량\n",
        "            crops_price,                           # 해당 농작물 월별 가격\n",
        "            diesel_price,                          # 월별 경유 가격\n",
        "            last_amount_import,                    # 전년 수입량\n",
        "            # 물가지수\n",
        "            total_pidx, prod_pidx, agricul_marine_prod_pidx, indust_prod_pidx, serv_pidx, pub_serv_pidx, per_serv_pidx, house_pidx,\n",
        "            ]\n",
        "\n",
        "    dataset.append(prams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtnE8nF3927h"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4aVA0E97aI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188b0650-eb27-40c5-b386-2299e156b4c3"
      },
      "source": [
        "''' 정규화 '''\n",
        "# last_prams\n",
        "norm_last = []\n",
        "for idx, pram in enumerate(last_prams) :\n",
        "    tmp_last = []\n",
        "    for next in range(0, (END_YEAR-START_YEAR)+1) :\n",
        "        tmp_df = pram\n",
        "\n",
        "        cur_year = START_YEAR + next\n",
        "        year_list = tmp_df.index.values.tolist()\n",
        "        if cur_year-4 < year_list[-1] : year_list = year_list[year_list.index(cur_year):len(year_list)] # 5년간 데이터가 없을 경우\n",
        "        else : year_list = year_list[year_list.index(cur_year):year_list.index(cur_year-4)+1]           # 5년간 데이터가 있는 경우\n",
        "\n",
        "        tmp_df = tmp_df.loc[year_list]\n",
        "        tmp_last.append(Normalization(tmp_df).to_numpy()[0])\n",
        "    norm_last.append(tmp_last)\n",
        "\n",
        "# prams\n",
        "for idx, data in enumerate(dataset) :\n",
        "    for i, pram in enumerate(data) :\n",
        "        pram = Normalization(pram)\n",
        "        pram = pram.to_numpy()\n",
        "\n",
        "        dataset[idx][i] = pram\n",
        "\n",
        "''' 데이터셋 구축 '''\n",
        "X_dataset = []\n",
        "y_dataset = []\n",
        "\n",
        "# X, y 데이터셋 구분\n",
        "for cur, year in enumerate(dataset) :\n",
        "    tmp_X1 = [[], [], [], [], []] # 1~5월\n",
        "    tmp_y1 = [] # 6월\n",
        "    tmp_X2 = [[], [], [], [] ,[]] # 7~11월\n",
        "    tmp_y2 = [] # 12월\n",
        "    for idx, data in enumerate(year) :\n",
        "        for month in range(0, 12) :\n",
        "            if idx == 12 : \n",
        "                if month == 5 : tmp_y1.append(data[month])\n",
        "                elif month == 11: tmp_y2.append(data[month])\n",
        "            else :\n",
        "                if month < 5 : tmp_X1[month].append(data[month])\n",
        "                elif month > 5 and month < 11 : tmp_X2[month-6].append(data[month])\n",
        "\n",
        "    for last_data in norm_last :\n",
        "        for month in tmp_X1 : month.append(last_data[cur])\n",
        "        for month in tmp_X2 : month.append(last_data[cur])\n",
        "    \n",
        "    X_dataset.append(tmp_X1)\n",
        "    y_dataset.append(tmp_y1)\n",
        "    X_dataset.append(tmp_X2)\n",
        "    y_dataset.append(tmp_y2)\n",
        "\n",
        "# 데이터 형변환\n",
        "X_dataset = np.array(X_dataset)\n",
        "y_dataset = np.array(y_dataset)\n",
        "\n",
        "# reshape X_dataset\n",
        "X_dataset = X_dataset.reshape(X_dataset.shape[0], X_dataset.shape[1] * X_dataset.shape[2], 1)\n",
        "\n",
        "# Data division (Train : Test = 8 : 2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.2)\n",
        "print(\"########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# Data division (Train : Validation = 8 : 2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "print(\"########## Train (X,) (y,) / Validation (X,) (y,) ##########\")\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Train + Validation (X,) (y,) / Test (X,) (y,) ##########\n",
            "(22, 120, 1) (22, 1) (6, 120, 1) (6, 1)\n",
            "########## Train (X,) (y,) / Validation (X,) (y,) ##########\n",
            "(17, 120, 1) (17, 1) (5, 120, 1) (5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P4ubOMj-YWG"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GpM_MnL-Ydz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652f80c7-61c3-4a3f-edd4-7d2462a660be"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(64,                    # 해당 층의 노드 개수\n",
        "                       input_shape=(17, 120, 1),    # input_shape=?\n",
        "                       return_sequences=True)))     # return_sequences == 각 시퀀스를 출력할지\n",
        "model.add(Dropout(0.005))                            # 과적합 방지용 Ex. Dropout 20%(==0.2)\n",
        "model.add(Dense(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.build(input_shape=(17, 120, 1))\n",
        "model.compile(loss=losses.MeanSquaredError(),\n",
        "              optimizer=Adam(learning_rate=0.0001), # pram ex. learning_rate=0.0001\n",
        "              metrics=[metrics.MeanSquaredError()]\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_28 (Bidirecti  (17, 120, 128)           33792     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (17, 120, 128)            0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (17, 120, 16)             2064      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (17, 120, 1)              17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,873\n",
            "Trainable params: 35,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQKnA-yk-bs5"
      },
      "source": [
        "### Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgorD0U-bLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac6a71ce-55dd-42bf-9349-9dcb30ced95d"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data = (X_val, y_val),\n",
        "                    batch_size = 20,\n",
        "                    epochs = 204,                     # Train set's 10%\n",
        "                    verbose = 1,                      # 0=silent, 1=progress bar, 2=one line per epoch.\n",
        "                    )\n",
        "\n",
        "# loss and acc graph (train and val)\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[[\"loss\", \"val_loss\"]].plot()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/204\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.1477 - mean_squared_error: 0.1477 - val_loss: 0.1175 - val_mean_squared_error: 0.1175\n",
            "Epoch 2/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1475 - mean_squared_error: 0.1475 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
            "Epoch 3/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1473 - mean_squared_error: 0.1473 - val_loss: 0.1180 - val_mean_squared_error: 0.1180\n",
            "Epoch 4/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1470 - mean_squared_error: 0.1470 - val_loss: 0.1183 - val_mean_squared_error: 0.1183\n",
            "Epoch 5/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1468 - mean_squared_error: 0.1468 - val_loss: 0.1186 - val_mean_squared_error: 0.1186\n",
            "Epoch 6/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1466 - mean_squared_error: 0.1466 - val_loss: 0.1188 - val_mean_squared_error: 0.1188\n",
            "Epoch 7/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1464 - mean_squared_error: 0.1464 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
            "Epoch 8/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1461 - mean_squared_error: 0.1461 - val_loss: 0.1194 - val_mean_squared_error: 0.1194\n",
            "Epoch 9/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1460 - mean_squared_error: 0.1460 - val_loss: 0.1197 - val_mean_squared_error: 0.1197\n",
            "Epoch 10/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1457 - mean_squared_error: 0.1457 - val_loss: 0.1200 - val_mean_squared_error: 0.1200\n",
            "Epoch 11/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1456 - mean_squared_error: 0.1456 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
            "Epoch 12/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1454 - mean_squared_error: 0.1454 - val_loss: 0.1206 - val_mean_squared_error: 0.1206\n",
            "Epoch 13/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1452 - mean_squared_error: 0.1452 - val_loss: 0.1209 - val_mean_squared_error: 0.1209\n",
            "Epoch 14/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1450 - mean_squared_error: 0.1450 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
            "Epoch 15/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1449 - mean_squared_error: 0.1449 - val_loss: 0.1216 - val_mean_squared_error: 0.1216\n",
            "Epoch 16/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1448 - mean_squared_error: 0.1448 - val_loss: 0.1219 - val_mean_squared_error: 0.1219\n",
            "Epoch 17/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1446 - mean_squared_error: 0.1446 - val_loss: 0.1222 - val_mean_squared_error: 0.1222\n",
            "Epoch 18/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1445 - mean_squared_error: 0.1445 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
            "Epoch 19/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1443 - mean_squared_error: 0.1443 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
            "Epoch 20/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1442 - mean_squared_error: 0.1442 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
            "Epoch 21/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1441 - mean_squared_error: 0.1441 - val_loss: 0.1236 - val_mean_squared_error: 0.1236\n",
            "Epoch 22/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1440 - mean_squared_error: 0.1440 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
            "Epoch 23/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1439 - mean_squared_error: 0.1439 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
            "Epoch 24/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1438 - mean_squared_error: 0.1438 - val_loss: 0.1246 - val_mean_squared_error: 0.1246\n",
            "Epoch 25/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1437 - mean_squared_error: 0.1437 - val_loss: 0.1250 - val_mean_squared_error: 0.1250\n",
            "Epoch 26/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1436 - mean_squared_error: 0.1436 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
            "Epoch 27/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1435 - mean_squared_error: 0.1435 - val_loss: 0.1256 - val_mean_squared_error: 0.1256\n",
            "Epoch 28/204\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1435 - mean_squared_error: 0.1435 - val_loss: 0.1260 - val_mean_squared_error: 0.1260\n",
            "Epoch 29/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1434 - mean_squared_error: 0.1434 - val_loss: 0.1263 - val_mean_squared_error: 0.1263\n",
            "Epoch 30/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1433 - mean_squared_error: 0.1433 - val_loss: 0.1267 - val_mean_squared_error: 0.1267\n",
            "Epoch 31/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1432 - mean_squared_error: 0.1432 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
            "Epoch 32/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1432 - mean_squared_error: 0.1432 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
            "Epoch 33/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1432 - mean_squared_error: 0.1432 - val_loss: 0.1276 - val_mean_squared_error: 0.1276\n",
            "Epoch 34/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1431 - mean_squared_error: 0.1431 - val_loss: 0.1280 - val_mean_squared_error: 0.1280\n",
            "Epoch 35/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1431 - mean_squared_error: 0.1431 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
            "Epoch 36/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1430 - mean_squared_error: 0.1430 - val_loss: 0.1286 - val_mean_squared_error: 0.1286\n",
            "Epoch 37/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1430 - mean_squared_error: 0.1430 - val_loss: 0.1289 - val_mean_squared_error: 0.1289\n",
            "Epoch 38/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1430 - mean_squared_error: 0.1430 - val_loss: 0.1292 - val_mean_squared_error: 0.1292\n",
            "Epoch 39/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - val_loss: 0.1295 - val_mean_squared_error: 0.1295\n",
            "Epoch 40/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - val_loss: 0.1297 - val_mean_squared_error: 0.1297\n",
            "Epoch 41/204\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - val_loss: 0.1300 - val_mean_squared_error: 0.1300\n",
            "Epoch 42/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - val_loss: 0.1302 - val_mean_squared_error: 0.1302\n",
            "Epoch 43/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
            "Epoch 44/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
            "Epoch 45/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
            "Epoch 46/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
            "Epoch 47/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
            "Epoch 48/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
            "Epoch 49/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
            "Epoch 50/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 51/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 52/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 53/204\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1321 - val_mean_squared_error: 0.1321\n",
            "Epoch 54/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1428 - mean_squared_error: 0.1428 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
            "Epoch 55/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
            "Epoch 56/204\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
            "Epoch 57/204\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
            "Epoch 58/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 59/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 60/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 61/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
            "Epoch 62/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1427 - mean_squared_error: 0.1427 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
            "Epoch 63/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
            "Epoch 64/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
            "Epoch 65/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 66/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 67/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 68/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
            "Epoch 69/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
            "Epoch 70/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
            "Epoch 71/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
            "Epoch 72/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1426 - mean_squared_error: 0.1426 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
            "Epoch 73/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
            "Epoch 74/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
            "Epoch 75/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
            "Epoch 76/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
            "Epoch 77/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1321 - val_mean_squared_error: 0.1321\n",
            "Epoch 78/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1321 - val_mean_squared_error: 0.1321\n",
            "Epoch 79/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1321 - val_mean_squared_error: 0.1321\n",
            "Epoch 80/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1425 - mean_squared_error: 0.1425 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 81/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 82/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 83/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 84/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 85/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 86/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 87/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 88/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 89/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 90/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 91/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 92/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1424 - mean_squared_error: 0.1424 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 93/204\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 94/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 95/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 96/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 97/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1423 - mean_squared_error: 0.1423 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 98/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 99/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 100/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 101/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 102/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 103/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 104/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 105/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 106/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 107/204\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 108/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1422 - mean_squared_error: 0.1422 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 109/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 110/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 111/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 112/204\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 113/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 114/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1420 - mean_squared_error: 0.1420 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 115/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 116/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1420 - mean_squared_error: 0.1420 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 117/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1420 - mean_squared_error: 0.1420 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 118/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1420 - mean_squared_error: 0.1420 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 119/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1420 - mean_squared_error: 0.1420 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 120/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 121/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 122/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 123/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 124/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 125/204\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 126/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1419 - mean_squared_error: 0.1419 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 127/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 128/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 129/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 130/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 131/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 132/204\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.1418 - mean_squared_error: 0.1418 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 133/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 134/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 135/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 136/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 137/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1416 - mean_squared_error: 0.1416 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 138/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1417 - mean_squared_error: 0.1417 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 139/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1416 - mean_squared_error: 0.1416 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 140/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1416 - mean_squared_error: 0.1416 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 141/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1416 - mean_squared_error: 0.1416 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 142/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1415 - mean_squared_error: 0.1415 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 143/204\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.1415 - mean_squared_error: 0.1415 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 144/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1415 - mean_squared_error: 0.1415 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 145/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1415 - mean_squared_error: 0.1415 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 146/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1415 - mean_squared_error: 0.1415 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 147/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1414 - mean_squared_error: 0.1414 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
            "Epoch 148/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1414 - mean_squared_error: 0.1414 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 149/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 150/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 151/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 152/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 153/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1412 - mean_squared_error: 0.1412 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 154/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1413 - mean_squared_error: 0.1413 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 155/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1412 - mean_squared_error: 0.1412 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 156/204\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1411 - mean_squared_error: 0.1411 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 157/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1411 - mean_squared_error: 0.1411 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 158/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1411 - mean_squared_error: 0.1411 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 159/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1410 - mean_squared_error: 0.1410 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 160/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1410 - mean_squared_error: 0.1410 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
            "Epoch 161/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1410 - mean_squared_error: 0.1410 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 162/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1409 - mean_squared_error: 0.1409 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 163/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1409 - mean_squared_error: 0.1409 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 164/204\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1409 - mean_squared_error: 0.1409 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 165/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1409 - mean_squared_error: 0.1409 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 166/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1408 - mean_squared_error: 0.1408 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
            "Epoch 167/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1408 - mean_squared_error: 0.1408 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
            "Epoch 168/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1407 - mean_squared_error: 0.1407 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
            "Epoch 169/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1406 - mean_squared_error: 0.1406 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
            "Epoch 170/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1406 - mean_squared_error: 0.1406 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
            "Epoch 171/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1405 - mean_squared_error: 0.1405 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
            "Epoch 172/204\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1405 - mean_squared_error: 0.1405 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
            "Epoch 173/204\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1404 - mean_squared_error: 0.1404 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
            "Epoch 174/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1404 - mean_squared_error: 0.1404 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
            "Epoch 175/204\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.1403 - mean_squared_error: 0.1403 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
            "Epoch 176/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1402 - mean_squared_error: 0.1402 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
            "Epoch 177/204\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1401 - mean_squared_error: 0.1401 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
            "Epoch 178/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1401 - mean_squared_error: 0.1401 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
            "Epoch 179/204\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.1400 - mean_squared_error: 0.1400 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
            "Epoch 180/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1399 - mean_squared_error: 0.1399 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
            "Epoch 181/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1398 - mean_squared_error: 0.1398 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
            "Epoch 182/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1397 - mean_squared_error: 0.1397 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
            "Epoch 183/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1396 - mean_squared_error: 0.1396 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
            "Epoch 184/204\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1395 - mean_squared_error: 0.1395 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
            "Epoch 185/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1393 - mean_squared_error: 0.1393 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
            "Epoch 186/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1392 - mean_squared_error: 0.1392 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
            "Epoch 187/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1391 - mean_squared_error: 0.1391 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
            "Epoch 188/204\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.1390 - mean_squared_error: 0.1390 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
            "Epoch 189/204\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1387 - mean_squared_error: 0.1387 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
            "Epoch 190/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1385 - mean_squared_error: 0.1385 - val_loss: 0.1304 - val_mean_squared_error: 0.1304\n",
            "Epoch 191/204\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1383 - mean_squared_error: 0.1383 - val_loss: 0.1303 - val_mean_squared_error: 0.1303\n",
            "Epoch 192/204\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.1380 - mean_squared_error: 0.1380 - val_loss: 0.1302 - val_mean_squared_error: 0.1302\n",
            "Epoch 193/204\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1378 - mean_squared_error: 0.1378 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
            "Epoch 194/204\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1374 - mean_squared_error: 0.1374 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
            "Epoch 195/204\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1371 - mean_squared_error: 0.1371 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
            "Epoch 196/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1366 - mean_squared_error: 0.1366 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
            "Epoch 197/204\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1361 - mean_squared_error: 0.1361 - val_loss: 0.1303 - val_mean_squared_error: 0.1303\n",
            "Epoch 198/204\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1356 - mean_squared_error: 0.1356 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
            "Epoch 199/204\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1349 - mean_squared_error: 0.1349 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
            "Epoch 200/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1343 - mean_squared_error: 0.1343 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
            "Epoch 201/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1337 - mean_squared_error: 0.1337 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
            "Epoch 202/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 0.1347 - val_mean_squared_error: 0.1347\n",
            "Epoch 203/204\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1329 - mean_squared_error: 0.1329 - val_loss: 0.1360 - val_mean_squared_error: 0.1360\n",
            "Epoch 204/204\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1327 - mean_squared_error: 0.1327 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6883dab190>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmw7-DI7-f2S"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJrzhLK1-hLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}